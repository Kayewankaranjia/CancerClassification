{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f878ed-f016-4c6f-a961-cf7ebb5df100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "from mlflow.models.signature import infer_signature#\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    auc,\n",
    "    brier_score_loss,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017400b9-d0ad-41d9-88e9-b853ad3262e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = f\"/cancer_classification_training\"\n",
    "run_name = \"cancer_classification_training\" + str(pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "full_model_name = \"cancer_classification_model\"\n",
    "\n",
    "LABEL = \"Target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b575f8e9-2eac-4852-829f-3c3bfb433f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining these up front to make mlflow experiments optional\n",
    "mlflow_metrics = {} # a place to pop new metrics into\n",
    "mlflow_figures = {} # a place to pop new matplotlib/sns figures into\n",
    "mlflow_tables = {} # a place to pop new dataframes into (keep it small!)\n",
    "mlflow_artifact_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "840220df-e769-4041-a3fb-289cc9b1f15e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def push_metric(metric_name: str, metric_value: any) -> None:\n",
    "    print(f\"Adding metric {metric_name}: {metric_value}\")\n",
    "    mlflow_metrics[metric_name] = metric_value\n",
    "\n",
    "def push_figure(figure_name: str, figure_value: any):\n",
    "    print(f\"Adding figure {figure_name}: {figure_value}\")\n",
    "    mlflow_figures[figure_name] = figure_value\n",
    "\n",
    "def push_table(table_name: str, table_value: any):\n",
    "    print(f\"Adding table {table_name}: {table_value}\")\n",
    "    mlflow_tables[table_name] = table_value\n",
    "\n",
    "def push_artifact(file_path: str):\n",
    "    print(f\"Adding artifact {file_path}\")\n",
    "    mlflow_artifact_paths.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d04cc46-0753-4331-a28c-ca48c3f82935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Get clean data\n",
    "\n",
    "def get_clean_data(filename: str) -> pd.DataFrame:\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_train_data(data: pd.DataFrame):\n",
    "    \"\"\"Get training data from the cleaned dataset.\"\"\"\n",
    "    # Split the data into features and Target\n",
    "    X = data\n",
    "    y = data['Target']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    # Stratify to ensure both classes are represented in train/test splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds = train_test_split(\n",
    "        X_train, test_size=0.1, random_state=20000, shuffle=True\n",
    "    )\n",
    "    X_train = X_train.drop(columns=['Target'])\n",
    "    X_val = val_ds.drop(columns=['Target'])\n",
    "    X_test = X_test.drop(columns=['Target'])\n",
    "    y_val = val_ds['Target']\n",
    "     \n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa501f7-c7c8-45d6-a3bd-2821f4fed735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the model metrics\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    \"\"\"Calculate model metrics.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    logloss = log_loss(y_true, y_proba)\n",
    "\n",
    "    return accuracy, precision, recall, f1, logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9182152f-657b-44dd-9ffd-424fe60f7d2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model_metrics(\n",
    "    model: lgb.Booster, X_test: pd.DataFrame, y_test: pd.Series\n",
    ") -> dict:\n",
    "    y_pred_probablity = model.predict(X_test)\n",
    "    pred_threshold = np.percentile(y_pred_probablity, 60)\n",
    "    y_pred_label = np.where(y_pred_probablity >= pred_threshold, 1, 0)\n",
    "\n",
    "    metrics = {\n",
    "        \"logloss\": log_loss(y_test, y_pred_probablity),\n",
    "        \"pred_threshold\": pred_threshold,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_label),        \n",
    "        \"f1_score\": f1_score(y_test, y_pred_label),\n",
    "        \"f05_score\": fbeta_score(y_test, y_pred_label, beta=0.5),\n",
    "        \"precision_score\": precision_score(y_test, y_pred_label),\n",
    "        \"recall_score\": recall_score(y_test, y_pred_label),\n",
    "        \"roc_auc_score\": roc_auc_score(y_test, y_pred_probablity),\n",
    "        \"y_real_mean\": y_test.mean(),\n",
    "        \"y_pred_mean\": y_pred_probablity.mean(),\n",
    "        \"iterations\": model.current_iteration(),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659af30c-67c9-469c-be78-8ad90e593ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "run = mlflow.start_run(run_name=run_name, description=f\"Building a model for {experiment_name}\")\n",
    "print(f\"creating run called {run.info.run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1341dcc-36f2-4534-bfb2-65afb846b3da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clean_df = get_clean_data('../data/clean.csv')\n",
    "push_metric(\"count_initial\", clean_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a622a398-e565-4b7d-8d23-ac214b4a5b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, X_val, Y_val = get_train_data(clean_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8355d6d0-dd2a-4ccd-9704-78b7c01d8a98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unsupported_cols = X_train.select_dtypes(exclude=['int', 'float', 'bool']).columns\n",
    "print(\"Columns with unsupported data types:\", unsupported_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd66eaf2-f1d7-427b-ba43-7b635eb11e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b19df456-47d6-4284-a252-941126e08975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def eval_logloss(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    return \"logloss\", log_loss(y_true, y_hat), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26c6e0b6-a7de-4649-b079-77b1ac9e95b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define constants\n",
    "PRIMARY_METRIC = \"logloss\"  # or \"f1\"\n",
    "ESTIMATORS = 50 \n",
    "EARLY_STOP = 5\n",
    "LEARNING_RATE = 0.045\n",
    "CATEGORICAL_FEATURES = []\n",
    "# Prepare datasets\n",
    "# Assuming X_train, y_train, X_valid, y_valid are predefined\n",
    "lgb_train_final = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=Y_train,\n",
    "    feature_name=list(X_train.columns),\n",
    "    categorical_feature=CATEGORICAL_FEATURES\n",
    ")\n",
    "\n",
    "lgb_valid = lgb.Dataset(X_val, label=Y_val, reference=lgb_train_final)\n",
    "\n",
    "# lgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train_final)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": PRIMARY_METRIC,\n",
    "    \"num_threads\": 16,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "}\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=EARLY_STOP),\n",
    "    lgb.log_evaluation(period=10),  # Adjust the period as needed\n",
    "]\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=lgb_train_final,\n",
    "    valid_sets=lgb_valid, \n",
    "    num_boost_round=ESTIMATORS,\n",
    "    feval=eval_logloss,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"Final model built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f9874ac-12db-4d8f-a987-db30708b3bc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics = get_model_metrics(\n",
    "    final_model, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6607ee2-e256-4583-b8ec-9aeefa5614fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for (metric_name, metric_value) in metrics.items():\n",
    "    push_metric(metric_name, metric_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot: Receiver Operating Characteristic (ROC) Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_proba = final_model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "auc_legend = (\n",
    "    \"AUC Score Interpretation:\\n\"\n",
    "    \"1.0       : Perfect model\\n\"\n",
    "    \"0.9–0.99  : Excellent\\n\"\n",
    "    \"0.8–0.9   : Good\\n\"\n",
    "    \"0.7–0.8   : Fair\\n\"\n",
    "    \"0.5       : No better than random\\n\"\n",
    "    \"< 0.5     : Worse than random\"\n",
    ")\n",
    "plt.gca().text(\n",
    "    1.05, 0.5, auc_legend,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=10,\n",
    "    verticalalignment='center',\n",
    "    bbox=dict(boxstyle=\"round,pad=0.5\", edgecolor=\"gray\", facecolor=\"#f9f9f9\")\n",
    ")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "push_figure(\"receiver_operating_characteristic.png\", plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot: Kernel Density Estimate (KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for label in Y_test.unique():\n",
    "    subset = final_model.predict(X_test[Y_test == label])\n",
    "    sns.kdeplot(subset, label=f\"Target={label}\", fill=True)\n",
    "plt.title(\"Kernel Density Estimate (KDE) of Predicted Probabilities by True Class\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "push_figure(\"kde_plot.png\", plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_matrix = confusion_matrix(Y_test, np.where(y_pred_proba >= metrics[\"pred_threshold\"], 1, 0))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "push_figure(\"confusion_matrix.png\", plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_importance_gain = lgb.plot_importance(final_model, max_num_features=50, importance_type=\"gain\")\n",
    "ax_importance_gain.figure.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "push_figure(\"feature_importance_gain.png\", ax_importance_gain.figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94592ffb-d98e-4d83-a685-ec288bf6c03f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"registering model as: {full_model_name}\")\n",
    "autolog_run = mlflow.last_active_run()\n",
    "model_uri = \"runs:/{}/models/final_model\".format(autolog_run.info.run_id)\n",
    "\n",
    "# create a signature for the model so that mlflow knows the inputs and outputs (we need this because we're not using mlflow.autolog)\n",
    "X_train_sample = pd.DataFrame(X_train[:10], columns=X_train.columns)\n",
    "signature = infer_signature(X_train_sample, final_model.predict(X_train_sample))\n",
    "\n",
    "mlflow.lightgbm.log_model(\n",
    "    final_model,\n",
    "    registered_model_name=full_model_name,\n",
    "    signature=signature\n",
    ")\n",
    "# this simply logs metadata about the dataset (not the data itself)\n",
    "mlflow.log_input(mlflow.data.from_pandas(X_test), context=\"test\")\n",
    "mlflow.log_input(mlflow.data.from_pandas(X_train), context=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7cff4a3-26e7-463d-bb49-3e5f37fa7f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if mlflow.active_run() == None:\n",
    "    raise Exception(\"A run hasn't been started\")\n",
    "\n",
    "\n",
    "# ADD other metrics\n",
    "for (metric_name, metric_value) in mlflow_metrics.items():\n",
    "    print(f\"logging other metric: {metric_name}=metric_value\")\n",
    "    mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "for (figure_name, figure) in mlflow_figures.items():\n",
    "    print(f\"logging figure: {figure_name}\")\n",
    "    mlflow.log_figure(figure, figure_name)\n",
    "\n",
    "for (table_name, table_df) in mlflow_tables.items():\n",
    "    print(f\"logging table: {table_name}\")\n",
    "    mlflow.log_table(table_df, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e029b1d-75ae-430a-bda4-bb34a33fdd17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/kayewan.karanjia@gmail.com/.bundle/CancerClassifier/dev/files/src/requirements.txt"
    ],
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "cancer_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
